{"cells": [{"cell_type": "code", "metadata": {}, "source": ["!pip install torch torchvision matplotlib\n", "import torch\n", "import torch.nn as nn\n", "import torch.nn.functional as F\n", "import torchvision\n", "from torchvision import datasets, transforms\n", "from torch.utils.data import DataLoader\n", "import matplotlib.pyplot as plt\n", "import numpy as np"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["from google.colab import drive\n", "drive.mount('/content/drive')"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["import zipfile\n", "import os\n", "zip_path = \"/content/drive/MyDrive/cats_and_dogs_filtered.zip\"\n", "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n", "    zip_ref.extractall(\"/content/data\")\n", "data_dir = \"/content/data/cats_and_dogs_filtered\""], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["transform = transforms.Compose([\n", "    transforms.Resize((128, 128)),\n", "    transforms.ToTensor()\n", "])\n", "\n", "train_data = datasets.ImageFolder(os.path.join(data_dir, \"train\"), transform=transform)\n", "test_data = datasets.ImageFolder(os.path.join(data_dir, \"validation\"), transform=transform)\n", "\n", "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n", "test_loader = DataLoader(test_data, batch_size=32)"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["class CatDogCNN(nn.Module):\n", "    def __init__(self):\n", "        super(CatDogCNN, self).__init__()\n", "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n", "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n", "        self.pool = nn.MaxPool2d(2, 2)\n", "        self.fc1 = nn.Linear(32 * 32 * 32, 128)\n", "        self.fc2 = nn.Linear(128, 2)\n", "\n", "    def forward(self, x):\n", "        x = self.pool(F.relu(self.conv1(x)))\n", "        x = self.pool(F.relu(self.conv2(x)))\n", "        x = x.view(-1, 32 * 32 * 32)\n", "        x = F.relu(self.fc1(x))\n", "        x = self.fc2(x)\n", "        return x"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n", "model = CatDogCNN().to(device)\n", "\n", "criterion = nn.CrossEntropyLoss()\n", "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n", "\n", "for epoch in range(5):\n", "    running_loss = 0.0\n", "    for images, labels in train_loader:\n", "        images, labels = images.to(device), labels.to(device)\n", "\n", "        optimizer.zero_grad()\n", "        outputs = model(images)\n", "        loss = criterion(outputs, labels)\n", "        loss.backward()\n", "        optimizer.step()\n", "\n", "        running_loss += loss.item()\n", "    print(f\"Epoch {epoch+1} - Loss: {running_loss:.4f}\")"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["correct = 0\n", "total = 0\n", "model.eval()\n", "with torch.no_grad():\n", "    for images, labels in test_loader:\n", "        images, labels = images.to(device), labels.to(device)\n", "        outputs = model(images)\n", "        _, preds = torch.max(outputs, 1)\n", "        correct += (preds == labels).sum().item()\n", "        total += labels.size(0)\n", "\n", "accuracy = 100 * correct / total\n", "print(f\"Test Accuracy: {accuracy:.2f}%\")"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["torch.save(model.state_dict(), \"/content/drive/MyDrive/cat_dog_cnn.pth\")"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["from PIL import Image\n", "\n", "def predict_image(image_path):\n", "    image = Image.open(image_path)\n", "    transform = transforms.Compose([\n", "        transforms.Resize((128, 128)),\n", "        transforms.ToTensor()\n", "    ])\n", "    image = transform(image).unsqueeze(0).to(device)\n", "    \n", "    model.eval()\n", "    with torch.no_grad():\n", "        output = model(image)\n", "        _, pred = torch.max(output, 1)\n", "    \n", "    return \"Dog\" if pred.item() == 1 else \"Cat\"\n", "\n", "# Example:\n", "# print(predict_image(\"/content/data/cats_and_dogs_filtered/validation/dogs/1001.jpg\"))"], "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.9"}}, "nbformat": 4, "nbformat_minor": 5}